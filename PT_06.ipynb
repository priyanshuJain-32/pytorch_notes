{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial 06 - Training Pipeline: Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in implementation\n",
    "\n",
    "1. Design model (input size, output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "- Forward pass: compute y_pred\n",
    "- Backward pass: gradients\n",
    "- Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we do not need to initialize the weights here\n",
    "\n",
    "x = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32) # Note we needed to create a list of lists\n",
    "y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "\n",
    "x_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = x.shape\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "# print(n_features)\n",
    "model = nn.Linear(in_features=input_size, out_features=output_size) # We implemented pytorch model instead of using our own forward prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict before training: f(5): -1.648\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predict before training: f(5): {model(x_test).item(): .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 1000\n",
    "\n",
    "# loss - Use the built in function here for loss from Pytorch similar to what we wrote manually\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# optimizer - we will use this optimizer to implement the updates and learning part of the model in our iterations\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 0 Loss = 40.476273; Weight = 0.009\n",
      "At 5 Loss = 6.587955; Weight = 1.052\n",
      "At 10 Loss = 1.134770; Weight = 1.472\n",
      "At 15 Loss = 0.255412; Weight = 1.643\n",
      "At 20 Loss = 0.111815; Weight = 1.714\n",
      "At 25 Loss = 0.086629; Weight = 1.744\n",
      "At 30 Loss = 0.080550; Weight = 1.758\n",
      "At 35 Loss = 0.077604; Weight = 1.766\n",
      "At 40 Loss = 0.075221; Weight = 1.771\n",
      "At 45 Loss = 0.072984; Weight = 1.775\n",
      "At 50 Loss = 0.070826; Weight = 1.779\n",
      "At 55 Loss = 0.068734; Weight = 1.782\n",
      "At 60 Loss = 0.066703; Weight = 1.786\n",
      "At 65 Loss = 0.064733; Weight = 1.789\n",
      "At 70 Loss = 0.062821; Weight = 1.792\n",
      "At 75 Loss = 0.060965; Weight = 1.795\n",
      "At 80 Loss = 0.059164; Weight = 1.798\n",
      "At 85 Loss = 0.057417; Weight = 1.801\n",
      "At 90 Loss = 0.055721; Weight = 1.804\n",
      "At 95 Loss = 0.054075; Weight = 1.807\n",
      "At 100 Loss = 0.052477; Weight = 1.810\n",
      "At 105 Loss = 0.050927; Weight = 1.813\n",
      "At 110 Loss = 0.049423; Weight = 1.816\n",
      "At 115 Loss = 0.047963; Weight = 1.818\n",
      "At 120 Loss = 0.046546; Weight = 1.821\n",
      "At 125 Loss = 0.045171; Weight = 1.824\n",
      "At 130 Loss = 0.043837; Weight = 1.826\n",
      "At 135 Loss = 0.042542; Weight = 1.829\n",
      "At 140 Loss = 0.041285; Weight = 1.831\n",
      "At 145 Loss = 0.040066; Weight = 1.834\n",
      "At 150 Loss = 0.038882; Weight = 1.836\n",
      "At 155 Loss = 0.037734; Weight = 1.839\n",
      "At 160 Loss = 0.036619; Weight = 1.841\n",
      "At 165 Loss = 0.035538; Weight = 1.844\n",
      "At 170 Loss = 0.034488; Weight = 1.846\n",
      "At 175 Loss = 0.033469; Weight = 1.848\n",
      "At 180 Loss = 0.032480; Weight = 1.850\n",
      "At 185 Loss = 0.031521; Weight = 1.853\n",
      "At 190 Loss = 0.030590; Weight = 1.855\n",
      "At 195 Loss = 0.029686; Weight = 1.857\n",
      "At 200 Loss = 0.028809; Weight = 1.859\n",
      "At 205 Loss = 0.027958; Weight = 1.861\n",
      "At 210 Loss = 0.027133; Weight = 1.863\n",
      "At 215 Loss = 0.026331; Weight = 1.865\n",
      "At 220 Loss = 0.025553; Weight = 1.867\n",
      "At 225 Loss = 0.024798; Weight = 1.869\n",
      "At 230 Loss = 0.024066; Weight = 1.871\n",
      "At 235 Loss = 0.023355; Weight = 1.873\n",
      "At 240 Loss = 0.022665; Weight = 1.875\n",
      "At 245 Loss = 0.021996; Weight = 1.877\n",
      "At 250 Loss = 0.021346; Weight = 1.879\n",
      "At 255 Loss = 0.020715; Weight = 1.881\n",
      "At 260 Loss = 0.020104; Weight = 1.882\n",
      "At 265 Loss = 0.019510; Weight = 1.884\n",
      "At 270 Loss = 0.018933; Weight = 1.886\n",
      "At 275 Loss = 0.018374; Weight = 1.888\n",
      "At 280 Loss = 0.017831; Weight = 1.889\n",
      "At 285 Loss = 0.017305; Weight = 1.891\n",
      "At 290 Loss = 0.016793; Weight = 1.892\n",
      "At 295 Loss = 0.016297; Weight = 1.894\n",
      "At 300 Loss = 0.015816; Weight = 1.896\n",
      "At 305 Loss = 0.015349; Weight = 1.897\n",
      "At 310 Loss = 0.014895; Weight = 1.899\n",
      "At 315 Loss = 0.014455; Weight = 1.900\n",
      "At 320 Loss = 0.014028; Weight = 1.902\n",
      "At 325 Loss = 0.013614; Weight = 1.903\n",
      "At 330 Loss = 0.013212; Weight = 1.905\n",
      "At 335 Loss = 0.012822; Weight = 1.906\n",
      "At 340 Loss = 0.012443; Weight = 1.907\n",
      "At 345 Loss = 0.012075; Weight = 1.909\n",
      "At 350 Loss = 0.011719; Weight = 1.910\n",
      "At 355 Loss = 0.011373; Weight = 1.912\n",
      "At 360 Loss = 0.011037; Weight = 1.913\n",
      "At 365 Loss = 0.010711; Weight = 1.914\n",
      "At 370 Loss = 0.010394; Weight = 1.915\n",
      "At 375 Loss = 0.010087; Weight = 1.917\n",
      "At 380 Loss = 0.009789; Weight = 1.918\n",
      "At 385 Loss = 0.009500; Weight = 1.919\n",
      "At 390 Loss = 0.009219; Weight = 1.920\n",
      "At 395 Loss = 0.008947; Weight = 1.922\n",
      "At 400 Loss = 0.008683; Weight = 1.923\n",
      "At 405 Loss = 0.008426; Weight = 1.924\n",
      "At 410 Loss = 0.008177; Weight = 1.925\n",
      "At 415 Loss = 0.007936; Weight = 1.926\n",
      "At 420 Loss = 0.007701; Weight = 1.927\n",
      "At 425 Loss = 0.007474; Weight = 1.928\n",
      "At 430 Loss = 0.007253; Weight = 1.929\n",
      "At 435 Loss = 0.007039; Weight = 1.930\n",
      "At 440 Loss = 0.006831; Weight = 1.931\n",
      "At 445 Loss = 0.006629; Weight = 1.932\n",
      "At 450 Loss = 0.006433; Weight = 1.933\n",
      "At 455 Loss = 0.006243; Weight = 1.934\n",
      "At 460 Loss = 0.006059; Weight = 1.935\n",
      "At 465 Loss = 0.005880; Weight = 1.936\n",
      "At 470 Loss = 0.005706; Weight = 1.937\n",
      "At 475 Loss = 0.005538; Weight = 1.938\n",
      "At 480 Loss = 0.005374; Weight = 1.939\n",
      "At 485 Loss = 0.005215; Weight = 1.940\n",
      "At 490 Loss = 0.005061; Weight = 1.941\n",
      "At 495 Loss = 0.004912; Weight = 1.942\n",
      "At 500 Loss = 0.004767; Weight = 1.943\n",
      "At 505 Loss = 0.004626; Weight = 1.944\n",
      "At 510 Loss = 0.004489; Weight = 1.944\n",
      "At 515 Loss = 0.004357; Weight = 1.945\n",
      "At 520 Loss = 0.004228; Weight = 1.946\n",
      "At 525 Loss = 0.004103; Weight = 1.947\n",
      "At 530 Loss = 0.003982; Weight = 1.948\n",
      "At 535 Loss = 0.003864; Weight = 1.948\n",
      "At 540 Loss = 0.003750; Weight = 1.949\n",
      "At 545 Loss = 0.003639; Weight = 1.950\n",
      "At 550 Loss = 0.003532; Weight = 1.951\n",
      "At 555 Loss = 0.003428; Weight = 1.951\n",
      "At 560 Loss = 0.003326; Weight = 1.952\n",
      "At 565 Loss = 0.003228; Weight = 1.953\n",
      "At 570 Loss = 0.003133; Weight = 1.954\n",
      "At 575 Loss = 0.003040; Weight = 1.954\n",
      "At 580 Loss = 0.002950; Weight = 1.955\n",
      "At 585 Loss = 0.002863; Weight = 1.956\n",
      "At 590 Loss = 0.002779; Weight = 1.956\n",
      "At 595 Loss = 0.002697; Weight = 1.957\n",
      "At 600 Loss = 0.002617; Weight = 1.958\n",
      "At 605 Loss = 0.002540; Weight = 1.958\n",
      "At 610 Loss = 0.002465; Weight = 1.959\n",
      "At 615 Loss = 0.002392; Weight = 1.959\n",
      "At 620 Loss = 0.002321; Weight = 1.960\n",
      "At 625 Loss = 0.002253; Weight = 1.961\n",
      "At 630 Loss = 0.002186; Weight = 1.961\n",
      "At 635 Loss = 0.002121; Weight = 1.962\n",
      "At 640 Loss = 0.002059; Weight = 1.962\n",
      "At 645 Loss = 0.001998; Weight = 1.963\n",
      "At 650 Loss = 0.001939; Weight = 1.963\n",
      "At 655 Loss = 0.001882; Weight = 1.964\n",
      "At 660 Loss = 0.001826; Weight = 1.965\n",
      "At 665 Loss = 0.001772; Weight = 1.965\n",
      "At 670 Loss = 0.001720; Weight = 1.966\n",
      "At 675 Loss = 0.001669; Weight = 1.966\n",
      "At 680 Loss = 0.001620; Weight = 1.967\n",
      "At 685 Loss = 0.001572; Weight = 1.967\n",
      "At 690 Loss = 0.001525; Weight = 1.968\n",
      "At 695 Loss = 0.001480; Weight = 1.968\n",
      "At 700 Loss = 0.001437; Weight = 1.969\n",
      "At 705 Loss = 0.001394; Weight = 1.969\n",
      "At 710 Loss = 0.001353; Weight = 1.969\n",
      "At 715 Loss = 0.001313; Weight = 1.970\n",
      "At 720 Loss = 0.001274; Weight = 1.970\n",
      "At 725 Loss = 0.001237; Weight = 1.971\n",
      "At 730 Loss = 0.001200; Weight = 1.971\n",
      "At 735 Loss = 0.001165; Weight = 1.972\n",
      "At 740 Loss = 0.001130; Weight = 1.972\n",
      "At 745 Loss = 0.001097; Weight = 1.973\n",
      "At 750 Loss = 0.001064; Weight = 1.973\n",
      "At 755 Loss = 0.001033; Weight = 1.973\n",
      "At 760 Loss = 0.001003; Weight = 1.974\n",
      "At 765 Loss = 0.000973; Weight = 1.974\n",
      "At 770 Loss = 0.000944; Weight = 1.975\n",
      "At 775 Loss = 0.000916; Weight = 1.975\n",
      "At 780 Loss = 0.000889; Weight = 1.975\n",
      "At 785 Loss = 0.000863; Weight = 1.976\n",
      "At 790 Loss = 0.000837; Weight = 1.976\n",
      "At 795 Loss = 0.000813; Weight = 1.976\n",
      "At 800 Loss = 0.000789; Weight = 1.977\n",
      "At 805 Loss = 0.000765; Weight = 1.977\n",
      "At 810 Loss = 0.000743; Weight = 1.977\n",
      "At 815 Loss = 0.000721; Weight = 1.978\n",
      "At 820 Loss = 0.000700; Weight = 1.978\n",
      "At 825 Loss = 0.000679; Weight = 1.978\n",
      "At 830 Loss = 0.000659; Weight = 1.979\n",
      "At 835 Loss = 0.000639; Weight = 1.979\n",
      "At 840 Loss = 0.000620; Weight = 1.979\n",
      "At 845 Loss = 0.000602; Weight = 1.980\n",
      "At 850 Loss = 0.000584; Weight = 1.980\n",
      "At 855 Loss = 0.000567; Weight = 1.980\n",
      "At 860 Loss = 0.000550; Weight = 1.981\n",
      "At 865 Loss = 0.000534; Weight = 1.981\n",
      "At 870 Loss = 0.000518; Weight = 1.981\n",
      "At 875 Loss = 0.000503; Weight = 1.981\n",
      "At 880 Loss = 0.000488; Weight = 1.982\n",
      "At 885 Loss = 0.000474; Weight = 1.982\n",
      "At 890 Loss = 0.000460; Weight = 1.982\n",
      "At 895 Loss = 0.000446; Weight = 1.982\n",
      "At 900 Loss = 0.000433; Weight = 1.983\n",
      "At 905 Loss = 0.000420; Weight = 1.983\n",
      "At 910 Loss = 0.000408; Weight = 1.983\n",
      "At 915 Loss = 0.000396; Weight = 1.983\n",
      "At 920 Loss = 0.000384; Weight = 1.984\n",
      "At 925 Loss = 0.000373; Weight = 1.984\n",
      "At 930 Loss = 0.000362; Weight = 1.984\n",
      "At 935 Loss = 0.000351; Weight = 1.984\n",
      "At 940 Loss = 0.000341; Weight = 1.985\n",
      "At 945 Loss = 0.000331; Weight = 1.985\n",
      "At 950 Loss = 0.000321; Weight = 1.985\n",
      "At 955 Loss = 0.000311; Weight = 1.985\n",
      "At 960 Loss = 0.000302; Weight = 1.986\n",
      "At 965 Loss = 0.000293; Weight = 1.986\n",
      "At 970 Loss = 0.000285; Weight = 1.986\n",
      "At 975 Loss = 0.000276; Weight = 1.986\n",
      "At 980 Loss = 0.000268; Weight = 1.986\n",
      "At 985 Loss = 0.000260; Weight = 1.987\n",
      "At 990 Loss = 0.000252; Weight = 1.987\n",
      "At 995 Loss = 0.000245; Weight = 1.987\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_iters):\n",
    "    # prediction = forward pass\n",
    "    y_pred = model(x) # Notice we are using pytorch model\n",
    "\n",
    "    # loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # gradient\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # empty gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch%5==0:\n",
    "        [w,b] = model.parameters()\n",
    "        print(f\"At {epoch} Loss = {l:.6f}; Weight = {w[0][0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict after training: f(5):  9.974\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predict after training: f(5): {model(x_test).item(): .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to design our pytorch model\n",
    "# We just need to subclass nn.Module and implement its functions\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
